{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ua-datalab/geospatial_2025/blob/main/notebooks/deepforest_colab_a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d05c59d-33da-44e3-a211-8efef2062846",
      "metadata": {
        "id": "3d05c59d-33da-44e3-a211-8efef2062846"
      },
      "source": [
        "## Tree Detection with DeepForest\n",
        "\n",
        "This jupyter notebook uses the python library DeepForest to identify and put bounding boxes around trees.\n",
        "\n",
        "If using the software, please cite as:\n",
        "Geographic Generalization in Airborne RGB Deep Learning Tree Detection Ben. G. Weinstein, Sergio Marconi, Stephanie A. Bohlman, Alina Zare, Ethan P. White bioRxiv 790071; doi: https://doi.org/10.1101/790071\n",
        "\n",
        "Documentation for DeepForest can be found at https://deepforest.readthedocs.io/en/latest/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "69370d7e-bcea-499b-b3fd-605389f1d5a1",
      "metadata": {
        "id": "69370d7e-bcea-499b-b3fd-605389f1d5a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0111b0-10e7-4b98-a038-46c4a42166db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.8/22.8 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m832.4/832.4 kB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m108.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.3/242.3 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for untokenize (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "#Install the deepforest python library. After installing, you may need to restart the kernel before moving to the next code snippet\n",
        "!pip install DeepForest --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uninstall the current version of albumentations\n",
        "!pip uninstall -y albumentations\n",
        "\n",
        "# Install a compatible version of albumentations\n",
        "!pip install albumentations==1.4.24"
      ],
      "metadata": {
        "id": "GmLVR3EyS-w-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df9aafc7-d3da-4169-99cb-1e8a18883740"
      },
      "id": "GmLVR3EyS-w-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: albumentations 2.0.8\n",
            "Uninstalling albumentations-2.0.8:\n",
            "  Successfully uninstalled albumentations-2.0.8\n",
            "Collecting albumentations==1.4.24\n",
            "  Downloading albumentations-1.4.24-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (1.16.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (2.11.7)\n",
            "Collecting albucore==0.0.23 (from albumentations==1.4.24)\n",
            "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.24) (4.12.0.88)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.23->albumentations==1.4.24) (3.12.6)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.23->albumentations==1.4.24) (6.5.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations==1.4.24) (0.4.1)\n",
            "Downloading albumentations-1.4.24-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.9/274.9 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: albucore, albumentations\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.24\n",
            "    Uninstalling albucore-0.0.24:\n",
            "      Successfully uninstalled albucore-0.0.24\n",
            "Successfully installed albucore-0.0.23 albumentations-1.4.24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c2a0e049-5661-4b76-a0c6-21377d9110be",
      "metadata": {
        "id": "c2a0e049-5661-4b76-a0c6-21377d9110be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3335ffb3-6b48-46b8-96fa-c75afc55b143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.24). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "##After restarting the kernel, import libraries into environment...\n",
        "from deepforest import main\n",
        "from deepforest import get_data\n",
        "from deepforest.utilities import boxes_to_shapefile\n",
        "from deepforest.utilities import shapefile_to_annotations\n",
        "from deepforest.preprocess import split_raster\n",
        "from deepforest.visualize import plot_predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import time\n",
        "import numpy\n",
        "import rasterio\n",
        "import geopandas as gpd\n",
        "from rasterio.plot import show\n",
        "import torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b6742c0c-5c29-46eb-bd60-534ddecb307a",
      "metadata": {
        "id": "b6742c0c-5c29-46eb-bd60-534ddecb307a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "a987d1df3dc948608121509fcd4a0c61",
            "d06911a55e0e42769cee2e7962b957c5",
            "f0fbcb77a5a44e28a042e737320e9b90",
            "17d49e014bd34e4595b4902f7b3222d2",
            "fed473ac09494bc786e44bcceb2b0dc1",
            "33a911cbd78a4acaba4ebc96aa4a6b8d",
            "5ffd511c37044fe39e956fa1f150592e",
            "61a9784e8af64f118e3d4aa77e4000fa",
            "6c29de5f736849ddaee932b5a4fccba2",
            "60f516f9120048198a5cf75cda493007",
            "7f44556c99c64f1985300379118f09fc",
            "bb88e2b1699e4b3f944c4ed81466de2b",
            "09cb49cac69d4747b4fa8e6e88e217d2",
            "9ba02a2af11a499d8fc3018a96393afc",
            "e104a018f9ea4bb8aa503d6327aff433",
            "107bbb38b81b4e1887eb434f2754e072",
            "1210eec3eb914170937432056f56d805",
            "df9eec45b74b4a25845c2628370ac612",
            "db22f8acb45a4cbfaa42bd28b6655705",
            "0f6e4015b3f5468c9ff151dd6875b7a7",
            "eec9027b625143af900c931aa5984917",
            "af8c0fb3d0a04de6b5191b51fe685fbc"
          ]
        },
        "outputId": "c158701e-9527-4f0b-9a91-b9b638b549e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading config file: /usr/local/lib/python3.12/dist-packages/deepforest/data/deepforest_config.yml\n",
            "Downloading: \"https://download.pytorch.org/models/retinanet_resnet50_fpn_coco-eeacb38b.pth\" to /root/.cache/torch/hub/checkpoints/retinanet_resnet50_fpn_coco-eeacb38b.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 130M/130M [00:00<00:00, 240MB/s]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/235 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a987d1df3dc948608121509fcd4a0c61"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading config file: /usr/local/lib/python3.12/dist-packages/deepforest/data/deepforest_config.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/129M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bb88e2b1699e4b3f944c4ed81466de2b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Bring a DeepForest pretrained model into environment. It is trained to identify trees from aerial imagery\n",
        "#It is located at https://huggingface.co/weecology/deepforest-tree\n",
        "model = main.deepforest()\n",
        "model.load_model(model_name=\"weecology/deepforest-tree\", revision=\"main\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Let's use GPU for prediction and training\n",
        "print(\"Current device is {}\".format(model.device))\n",
        "model.to(\"cuda\")\n",
        "print(\"Current device is {}\".format(model.device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANONIkd3afJz",
        "outputId": "8f245891-b1a7-4912-bf29-241a7d53bf2d"
      },
      "id": "ANONIkd3afJz",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current device is cpu\n",
            "Current device is cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27819458-7055-4330-ab31-a8e6be7e25d6",
      "metadata": {
        "id": "27819458-7055-4330-ab31-a8e6be7e25d6"
      },
      "source": [
        "## Predict Tree Crowns on Raw (non-georeferenced images)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Path for the image you want to ID trees.\n",
        "#These are non-georeferenced single jpeg drone image located in Cyverse datastore\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/commons/cyverse_curated/Gillan_Ecosphere_2021/raw_images/May_2019/15-g2/100_0123/100_0123_0086.JPG\n",
        "image_path = get_data(\"/content/100_0123_0086.JPG\")\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/DJI_0184.jpeg\n",
        "image_path2 = get_data(\"/content/DJI_0184.jpeg\")\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/100_0407_0064.jpeg\n",
        "image_path3 = get_data(\"/content/100_0407_0064.jpeg\")\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/DJI_0468.jpeg\n",
        "image_path4 = get_data(\"/content/DJI_0468.jpeg\")\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/101_0472_0074.jpeg\n",
        "image_path5 = get_data(\"/content/101_0472_0074.jpeg\")\n"
      ],
      "metadata": {
        "id": "YK8NqKlO_qm_"
      },
      "id": "YK8NqKlO_qm_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd5e2b9f-0501-4bff-bd9e-64eeb0ef7c3e",
      "metadata": {
        "id": "cd5e2b9f-0501-4bff-bd9e-64eeb0ef7c3e"
      },
      "outputs": [],
      "source": [
        "#Identify and put bounding boxes around all trees in the image\n",
        "#This will create a table showing image coordinates of every predicted tree\n",
        "#The 'score' is the confidence that the prediction is correct. Values closer to 1 are better.\n",
        "trees = model.predict_image(path=image_path3, return_plot = False)\n",
        "trees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e99105ef-36ed-420e-aed4-0b83eb7608c9",
      "metadata": {
        "id": "e99105ef-36ed-420e-aed4-0b83eb7608c9"
      },
      "outputs": [],
      "source": [
        "#Show the image with the bounding boxes\n",
        "plot = model.predict_image(path=image_path3, return_plot = True, color=(0, 255, 255), thickness=6)\n",
        "plt.imshow(plot[:,:,::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c01de3a-c409-48db-aa3e-9d42239e327f",
      "metadata": {
        "id": "5c01de3a-c409-48db-aa3e-9d42239e327f"
      },
      "source": [
        "## Predict Tree Crowns on Georeferenced Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff50dfc-dd00-43ef-8bc8-c5834427e5fc",
      "metadata": {
        "id": "4ff50dfc-dd00-43ef-8bc8-c5834427e5fc"
      },
      "outputs": [],
      "source": [
        "#Set the path for a georeferenced image you want to predict tree crowns\n",
        "\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/hole_17_ortho_utm.tif\n",
        "raster_path = get_data(\"/content/hole_17_ortho_utm.tif\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # opens a dialog box to select files\n"
      ],
      "metadata": {
        "id": "QQ7CfzYYYyZK"
      },
      "id": "QQ7CfzYYYyZK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c5b6a04e-4ca0-4d51-9982-aa47f93e11d0",
      "metadata": {
        "id": "c5b6a04e-4ca0-4d51-9982-aa47f93e11d0"
      },
      "outputs": [],
      "source": [
        "##Predict tree crowns on a georeferenced image\n",
        "predicted_raster = model.predict_tile(raster_path, return_plot = True, patch_size=1000, patch_overlap=0.25, color=(255, 255, 0), thickness=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8a53f0a-ca24-4e82-875f-1a69b7c869e7",
      "metadata": {
        "id": "d8a53f0a-ca24-4e82-875f-1a69b7c869e7"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(predicted_raster)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ce5727a-1bba-4f45-b982-2fbd82285ff8",
      "metadata": {
        "id": "7ce5727a-1bba-4f45-b982-2fbd82285ff8"
      },
      "source": [
        "## Improve Model with Training\n",
        "If the pre-trained model does not identify all trees correclty, then we want to improve the model by adding some training data and fine-tuning the model.\n",
        "Manual labeling of trees (bounding boxes) can be done in QGIS. The output should be a polygon shapefile (.shp). Instructions for using QGIS is [here](https://github.com/ua-datalab/Geospatial_Workshops/wiki/Drone-Image-Analysis-%E2%80%90-Deep-Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acd9b1b-e735-40ba-a8d1-4287dfdcd4f9",
      "metadata": {
        "id": "3acd9b1b-e735-40ba-a8d1-4287dfdcd4f9"
      },
      "outputs": [],
      "source": [
        "#Define data paths in preparation to convert .shp to annotation dataframe that can be used for training\n",
        "## I have found that it is important that the orthomosaic and shapefiles used should have map projections (e.g., UTM). Otherwise, there will be a shift problem in the `shapefile_to_annotations` step.\n",
        "\n",
        "# training data imagery path\n",
        "# We are using the golf course orthomosaic geotiff\n",
        "train_image_path = get_data(\"/content/hole_17_ortho_utm.tif\")\n",
        "\n",
        "# the directory that has the training data imagery\n",
        "train_image_dir = os.path.dirname(train_image_path)\n",
        "\n",
        "# the name of the training imagery\n",
        "image_name = os.path.basename(train_image_path)\n",
        "\n",
        "# shapefile path\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/golf_train_utm.shp\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/golf_train_utm.shx\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/golf_train_utm.dbf\n",
        "!wget https://data.cyverse.org/dav-anon/iplant/projects/cyverse_training/datalab/nextgen_geospatial/golf_train_utm.prj\n",
        "\n",
        "shp_path = \"/content/golf_train_utm.shp\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7471ca25-5d5b-472f-8d2d-cc65fdcc7076",
      "metadata": {
        "id": "7471ca25-5d5b-472f-8d2d-cc65fdcc7076"
      },
      "outputs": [],
      "source": [
        "## Show shapefile overlayed on orthomosaic\n",
        "\n",
        "# Open the GeoTIFF file\n",
        "with rasterio.open(train_image_path) as src:\n",
        "    fig, ax = plt.subplots(figsize=(20, 20))\n",
        "    show(src, ax=ax)\n",
        "\n",
        "    # Read the shapefile\n",
        "    shapefile = gpd.read_file(shp_path)\n",
        "\n",
        "    # Plot the shapefile on top of the GeoTIFF\n",
        "    shapefile.plot(ax=ax, facecolor='none', edgecolor='yellow')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a4522e0-5baf-40e0-8ce7-78b7b0c390a5",
      "metadata": {
        "id": "0a4522e0-5baf-40e0-8ce7-78b7b0c390a5"
      },
      "outputs": [],
      "source": [
        "##Convert .shp (shapefile) to annoation that can be ingested by DeepForest\n",
        "savedir = \"/content\"\n",
        "df = shapefile_to_annotations(shapefile=shp_path, rgb=train_image_path, geometry_type='bbox', savedir=savedir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23a3cd0f-f795-4f0a-87c6-dad756cfebb2",
      "metadata": {
        "id": "23a3cd0f-f795-4f0a-87c6-dad756cfebb2"
      },
      "outputs": [],
      "source": [
        "#Write training annotation dataframe to csv file\n",
        "df.to_csv(os.path.join(savedir, \"labels_pixel_coords.csv\"), index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b63fe9f-9b15-4ea8-8fb8-560840eec319",
      "metadata": {
        "id": "7b63fe9f-9b15-4ea8-8fb8-560840eec319"
      },
      "outputs": [],
      "source": [
        "#Show the annotation\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c2f6aa8-c97a-4012-82ce-d7f30af8d3a4",
      "metadata": {
        "scrolled": true,
        "id": "4c2f6aa8-c97a-4012-82ce-d7f30af8d3a4"
      },
      "outputs": [],
      "source": [
        "## Display the annotation on the orthomosaic\n",
        "\n",
        "rasterio_src = rasterio.open(train_image_path)\n",
        "\n",
        "image = rasterio_src.read()\n",
        "image = numpy.rollaxis(image, 0, 3)\n",
        "\n",
        "fig = plot_predictions(image, df, color=(255, 255, 0), thickness=20)\n",
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(fig)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8500b69-8b50-4358-b683-8aa38728030d",
      "metadata": {
        "id": "e8500b69-8b50-4358-b683-8aa38728030d"
      },
      "outputs": [],
      "source": [
        "##This will split a large georeferenced image (and it's labels) into smaller pieces. This prevents running out of memory.\n",
        "annotation_path = os.path.join(savedir, \"labels_pixel_coords.csv\")\n",
        "\n",
        "#create a directory where the smaller images will be stored\n",
        "crop_dir = os.path.join(savedir, 'train_data')\n",
        "\n",
        "# Do the split and write out the cropped images as .png files.\n",
        "#Also write a new annotation table (csv) that lists all of the label coordinates and the cropped image they belong to.\n",
        "output_crops = split_raster(path_to_raster=train_image_path,\n",
        "                            annotations_file=annotation_path,\n",
        "                            base_dir=crop_dir,\n",
        "                            patch_size=1100,  #1100x1100 pixels\n",
        "                            patch_overlap=0.25, #cropped image overlap. This is useful because label boxes may be on the edge of cropped images.\n",
        "                            allow_empty=False)\n",
        "\n",
        "print(f\"Number of tree crown annotations: {len(output_crops)}\")\n",
        "output_crops"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38c55fd6-6309-4e27-b5b3-6c296a862990",
      "metadata": {
        "id": "38c55fd6-6309-4e27-b5b3-6c296a862990"
      },
      "source": [
        "### Split annotation data into training and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e007f55f-c4a6-460b-ba99-0b15ec537e20",
      "metadata": {
        "id": "e007f55f-c4a6-460b-ba99-0b15ec537e20"
      },
      "outputs": [],
      "source": [
        "#identify all of the cropped images as an array\n",
        "image_paths = output_crops.image_path.unique()\n",
        "\n",
        "#Of the unique cropped image paths, randomly select 25% of them\n",
        "validation_paths = numpy.random.choice(image_paths, int(len(image_paths)*0.25))\n",
        "\n",
        "#Get the individual tree annotation from the 25% cropped images\n",
        "validation_annotations = output_crops.loc[output_crops.image_path.isin(validation_paths)]\n",
        "\n",
        "#Get the individual tree annotations from the remaining 75% cropped images\n",
        "train_annotations = output_crops.loc[~output_crops.image_path.isin(validation_paths)]\n",
        "\n",
        "#Print out the number of training and testing tree crown annotations\n",
        "train_annotations.head()\n",
        "print(\"There are {} training crown annotations\".format(train_annotations.shape[0]))\n",
        "print(\"There are {} test crown annotations\".format(validation_annotations.shape[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5d5d357-199d-4340-98bc-edcbd660369d",
      "metadata": {
        "id": "b5d5d357-199d-4340-98bc-edcbd660369d"
      },
      "outputs": [],
      "source": [
        "## Write training and validation annotations to separate csv files\n",
        "\n",
        "#save to file and create the file dir\n",
        "training_file= os.path.join(crop_dir,\"train.csv\")\n",
        "validation_file= os.path.join(crop_dir,\"valid.csv\")\n",
        "#Write window annotations file without a header row, same location as the \"base_dir\" above.\n",
        "train_annotations.to_csv(training_file,index=False)\n",
        "validation_annotations.to_csv(validation_file,index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61c8ac15-e8ed-4ffa-97c0-5ec1963cfae1",
      "metadata": {
        "id": "61c8ac15-e8ed-4ffa-97c0-5ec1963cfae1"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c93d670-efc9-4a47-bca8-7157425ba6b2",
      "metadata": {
        "id": "4c93d670-efc9-4a47-bca8-7157425ba6b2"
      },
      "outputs": [],
      "source": [
        "##Set parameters for the training run\n",
        "\n",
        "#Define the pre-trained model\n",
        "model = main.deepforest()\n",
        "\n",
        "model.config['gpus'] = '-1' #move to GPU and use all the GPU resources\n",
        "\n",
        "#model.config[\"save-snapshot\"] = False\n",
        "#model.config[\"train\"][\"fast_dev_run\"] = True\n",
        "\n",
        "#The annotation table\n",
        "model.config[\"train\"][\"csv_file\"] = training_file\n",
        "#The directory where the training imagery is located\n",
        "model.config[\"train\"][\"root_dir\"] = os.path.dirname(training_file)\n",
        "\n",
        "model.config[\"score_thresh\"] = 0.4\n",
        "model.config[\"train\"]['epochs'] = 4\n",
        "\n",
        "model.config[\"validation\"][\"csv_file\"] = validation_file\n",
        "model.config[\"validation\"][\"root_dir\"] = os.path.dirname(validation_file)\n",
        "\n",
        "\n",
        "model.create_trainer()\n",
        "\n",
        "model.use_release()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d5f8efb-a7e2-4c75-acc4-ea5ebcb0dc50",
      "metadata": {
        "id": "6d5f8efb-a7e2-4c75-acc4-ea5ebcb0dc50"
      },
      "outputs": [],
      "source": [
        "##TRAIN THE MODEL!\n",
        "#You can watch the GPU usage by using nvtop (sudo apt install nvtop)\n",
        "start_time = time.time()\n",
        "model.trainer.fit(model)\n",
        "print(f\"--- Training on GPU: {(time.time() - start_time):.2f} seconds ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7478be6e-2f32-4c1e-ab35-05a102e2299f",
      "metadata": {
        "id": "7478be6e-2f32-4c1e-ab35-05a102e2299f"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "d425f1a4-b4b7-4887-8c78-f97a0ff42794",
      "metadata": {
        "id": "d425f1a4-b4b7-4887-8c78-f97a0ff42794"
      },
      "source": [
        "## Visualize the prediction after model fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cd1b40d-5974-4c53-aa68-97471ad6f918",
      "metadata": {
        "id": "6cd1b40d-5974-4c53-aa68-97471ad6f918"
      },
      "outputs": [],
      "source": [
        "##Predict tree crowns on a georeferenced image\n",
        "predicted_raster = model.predict_tile(raster_path, return_plot = True, patch_size=1000, patch_overlap=0.25, color=(255, 255, 0), thickness=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75f1f1f4-9550-4e01-a775-8f90cbbe39bd",
      "metadata": {
        "id": "75f1f1f4-9550-4e01-a775-8f90cbbe39bd"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))\n",
        "plt.imshow(predicted_raster)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5752fc31-1340-4204-9934-c2e8e7f662b5",
      "metadata": {
        "id": "5752fc31-1340-4204-9934-c2e8e7f662b5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "8fa637b2-220c-4c17-ac70-92710974a06c",
      "metadata": {
        "id": "8fa637b2-220c-4c17-ac70-92710974a06c"
      },
      "source": [
        "## Output and save prediction results for each image crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ecc787f-e3d9-437d-9201-09ac24b69b7c",
      "metadata": {
        "id": "3ecc787f-e3d9-437d-9201-09ac24b69b7c"
      },
      "outputs": [],
      "source": [
        "save_dir = os.path.join(savedir, 'pred_result')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "results = model.evaluate(training_file, os.path.dirname(training_file), iou_threshold = 0.4, savedir= save_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f360004-00e3-4e8a-909e-918d3bbb4963",
      "metadata": {
        "id": "9f360004-00e3-4e8a-909e-918d3bbb4963"
      },
      "outputs": [],
      "source": [
        "## Output and save validation results for each image crop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9958f824-25ff-411d-a57a-3f1d81ea197c",
      "metadata": {
        "scrolled": true,
        "id": "9958f824-25ff-411d-a57a-3f1d81ea197c"
      },
      "outputs": [],
      "source": [
        "save_dir = os.path.join(savedir, 'valid_result')\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "results = model.evaluate(validation_file, os.path.dirname(validation_file), iou_threshold = 0.4, savedir= save_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22989035-5aaa-468f-836f-47c8dd3d4497",
      "metadata": {
        "id": "22989035-5aaa-468f-836f-47c8dd3d4497"
      },
      "source": [
        "## Assessing the Quality of our Tree Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5933db49-0923-419b-8384-d7fca01bf2e0",
      "metadata": {
        "id": "5933db49-0923-419b-8384-d7fca01bf2e0"
      },
      "outputs": [],
      "source": [
        "#show assessment of results\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd50637a-023a-4d44-8f23-59a11dba49d6",
      "metadata": {
        "id": "dd50637a-023a-4d44-8f23-59a11dba49d6"
      },
      "outputs": [],
      "source": [
        "results['results']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f40aa4b-5c30-4222-a72f-6e64cca2950d",
      "metadata": {
        "id": "9f40aa4b-5c30-4222-a72f-6e64cca2950d"
      },
      "outputs": [],
      "source": [
        "results['box_precision']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e60052e-ea87-4881-9f05-a58602742d03",
      "metadata": {
        "id": "3e60052e-ea87-4881-9f05-a58602742d03"
      },
      "outputs": [],
      "source": [
        "results[\"box_recall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b9ffcf2-956e-40fd-8b7a-ff865941ee0b",
      "metadata": {
        "id": "3b9ffcf2-956e-40fd-8b7a-ff865941ee0b"
      },
      "outputs": [],
      "source": [
        "results[\"class_recall\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef89f449-f3e9-4b62-a244-bd2e337b9693",
      "metadata": {
        "id": "ef89f449-f3e9-4b62-a244-bd2e337b9693"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "328a1c0e-f62d-4403-9183-55eef4f1d410",
      "metadata": {
        "id": "328a1c0e-f62d-4403-9183-55eef4f1d410"
      },
      "source": [
        "## Save and load the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3acd3841-da3c-471f-95a1-03ea763d6724",
      "metadata": {
        "id": "3acd3841-da3c-471f-95a1-03ea763d6724"
      },
      "outputs": [],
      "source": [
        "#Save the fine-tuned model out to your storage\n",
        "save_model_dir = os.path.join(savedir, 'golf_course_deepforest.pt')\n",
        "torch.save(model.model.state_dict(),save_model_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87c700fd-4958-42c1-aa83-b79c26039c24",
      "metadata": {
        "id": "87c700fd-4958-42c1-aa83-b79c26039c24"
      },
      "outputs": [],
      "source": [
        "#Bring existing model into environment\n",
        "fine_tuned_model = main.deepforest()\n",
        "fine_tuned_model.model.load_state_dict(torch.load(save_model_dir))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Fine-tuned model to Hugging Face"
      ],
      "metadata": {
        "id": "BwbYKPW1r9y2"
      },
      "id": "BwbYKPW1r9y2"
    },
    {
      "cell_type": "code",
      "source": [
        "#Install python libraries that allow you to connect with Hugging Face\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "2R9bSuBusGn-"
      },
      "id": "2R9bSuBusGn-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input your Hugging Face username toke to authenticate your account\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "bcvvHTv0sGdH"
      },
      "id": "bcvvHTv0sGdH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Push fine-tuned model up to Hugging Face\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "# Set up repository details\n",
        "repo_name = \"deepforest_fine_tuning\"\n",
        "model_file = \"/content/golf_course_deepforest.pt\"\n",
        "\n",
        "# Create a new repo if it doesn't exist\n",
        "#api = HfApi()\n",
        "#api.create_repo(repo_name)\n",
        "\n",
        "# Upload model to Hugging Face\n",
        "api.upload_file(\n",
        "    path_or_fileobj=model_file,   # Path to your .pt file\n",
        "    repo_id=f\"jgillan/{repo_name}\",\n",
        "    path_in_repo=\"golf_course_deepforest.pt\"  # The name you want for the file on the Hub\n",
        ")\n"
      ],
      "metadata": {
        "id": "TtiYci6VuOQh"
      },
      "id": "TtiYci6VuOQh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a model from Hugging Face and bring into Colab"
      ],
      "metadata": {
        "id": "A-HtLOST9Qju"
      },
      "id": "A-HtLOST9Qju"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Download the .pt file from Hugging Face\n",
        "model_file = hf_hub_download(repo_id=\"jgillan/deepforest_fine_tuning\", filename=\"golf_course_deepforest.pt\")\n",
        "\n",
        "fine_tuned_model = main.deepforest()\n",
        "fine_tuned_model.model.load_state_dict(torch.load(model_file))"
      ],
      "metadata": {
        "id": "fne1cd-x5cH9"
      },
      "id": "fne1cd-x5cH9",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a987d1df3dc948608121509fcd4a0c61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d06911a55e0e42769cee2e7962b957c5",
              "IPY_MODEL_f0fbcb77a5a44e28a042e737320e9b90",
              "IPY_MODEL_17d49e014bd34e4595b4902f7b3222d2"
            ],
            "layout": "IPY_MODEL_fed473ac09494bc786e44bcceb2b0dc1"
          }
        },
        "d06911a55e0e42769cee2e7962b957c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33a911cbd78a4acaba4ebc96aa4a6b8d",
            "placeholder": "​",
            "style": "IPY_MODEL_5ffd511c37044fe39e956fa1f150592e",
            "value": "config.json: 100%"
          }
        },
        "f0fbcb77a5a44e28a042e737320e9b90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61a9784e8af64f118e3d4aa77e4000fa",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c29de5f736849ddaee932b5a4fccba2",
            "value": 235
          }
        },
        "17d49e014bd34e4595b4902f7b3222d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60f516f9120048198a5cf75cda493007",
            "placeholder": "​",
            "style": "IPY_MODEL_7f44556c99c64f1985300379118f09fc",
            "value": " 235/235 [00:00&lt;00:00, 30.3kB/s]"
          }
        },
        "fed473ac09494bc786e44bcceb2b0dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a911cbd78a4acaba4ebc96aa4a6b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ffd511c37044fe39e956fa1f150592e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61a9784e8af64f118e3d4aa77e4000fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c29de5f736849ddaee932b5a4fccba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60f516f9120048198a5cf75cda493007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f44556c99c64f1985300379118f09fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb88e2b1699e4b3f944c4ed81466de2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09cb49cac69d4747b4fa8e6e88e217d2",
              "IPY_MODEL_9ba02a2af11a499d8fc3018a96393afc",
              "IPY_MODEL_e104a018f9ea4bb8aa503d6327aff433"
            ],
            "layout": "IPY_MODEL_107bbb38b81b4e1887eb434f2754e072"
          }
        },
        "09cb49cac69d4747b4fa8e6e88e217d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1210eec3eb914170937432056f56d805",
            "placeholder": "​",
            "style": "IPY_MODEL_df9eec45b74b4a25845c2628370ac612",
            "value": "model.safetensors: 100%"
          }
        },
        "9ba02a2af11a499d8fc3018a96393afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db22f8acb45a4cbfaa42bd28b6655705",
            "max": 129049980,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f6e4015b3f5468c9ff151dd6875b7a7",
            "value": 129049980
          }
        },
        "e104a018f9ea4bb8aa503d6327aff433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eec9027b625143af900c931aa5984917",
            "placeholder": "​",
            "style": "IPY_MODEL_af8c0fb3d0a04de6b5191b51fe685fbc",
            "value": " 129M/129M [00:02&lt;00:00, 88.0MB/s]"
          }
        },
        "107bbb38b81b4e1887eb434f2754e072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1210eec3eb914170937432056f56d805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df9eec45b74b4a25845c2628370ac612": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db22f8acb45a4cbfaa42bd28b6655705": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f6e4015b3f5468c9ff151dd6875b7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eec9027b625143af900c931aa5984917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af8c0fb3d0a04de6b5191b51fe685fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}